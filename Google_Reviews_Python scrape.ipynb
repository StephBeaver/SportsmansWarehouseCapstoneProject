{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1TgCj7T7CNw-_fRhr8Z3yqLvCe665TGR2","timestamp":1748528590301},{"file_id":"1ZNFewd90_zzmtrZgpcr3xOccF9UntedL","timestamp":1748365978910},{"file_id":"1RtxzOMRDZCPW3nRwDgLAV7AHIkqX4_WC","timestamp":1748361807193},{"file_id":"1r7ADxCCkdGPx9RLVZgLRuHJq4EhuUgMn","timestamp":1748356748127},{"file_id":"1mwA62UKdfaiqQKnGoFkI9LhG1FzkZdCn","timestamp":1748234148594},{"file_id":"12mUzoIKKHnU52bSgkwnJtfS6IItt1M6H","timestamp":1748231680862},{"file_id":"1RVrgVrq0feUf6Prj4Q0tbsoKlQMfKgGz","timestamp":1748227571806}],"mount_file_id":"1RVrgVrq0feUf6Prj4Q0tbsoKlQMfKgGz","authorship_tag":"ABX9TyMcjJudWULren09xvpsqyXh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Stephanie Beaver**\n","**Capstone Project**\n","**Working code completed on May 30 2025**\n","Scrapes google maps reviews of all stores in regions that the search is for. deposits them in HTML format into a temporary colab folder. Tracks which individual stores (URLs) are successfully scraped.\n"],"metadata":{"id":"Rok8o_PMvl4z"}},{"cell_type":"code","source":["import sys\n","!{sys.executable} -m pip install selenium\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsjYpraV1MKr","executionInfo":{"status":"ok","timestamp":1749748058033,"user_tz":360,"elapsed":9947,"user":{"displayName":"Stephanie Beaver","userId":"05177577234001440376"}},"outputId":"4296e3ff-983b-4c7d-b526-3006e3aa4593"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.33.0-py3-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: urllib3~=2.4.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (2.4.0)\n","Collecting trio~=0.30.0 (from selenium)\n","  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting trio-websocket~=0.12.2 (from selenium)\n","  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: certifi>=2025.4.26 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.4.26)\n","Collecting typing_extensions~=4.13.2 (from selenium)\n","  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n","Collecting outcome (from trio~=0.30.0->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n","Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n","Downloading selenium-4.33.0-py3-none-any.whl (9.4 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n","Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Installing collected packages: wsproto, typing_extensions, outcome, trio, trio-websocket, selenium\n","  Attempting uninstall: typing_extensions\n","    Found existing installation: typing_extensions 4.14.0\n","    Uninstalling typing_extensions-4.14.0:\n","      Successfully uninstalled typing_extensions-4.14.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed outcome-1.3.0.post0 selenium-4.33.0 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.13.2 wsproto-1.2.0\n"]}]},{"cell_type":"code","source":["pip install dateparser"],"metadata":{"id":"eYpyIhPv9_tk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749864222599,"user_tz":360,"elapsed":8392,"user":{"displayName":"Stephanie Beaver","userId":"05177577234001440376"}},"outputId":"6f31edbe-de83-43ca-80b6-759473c36107"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dateparser\n","  Downloading dateparser-1.2.1-py3-none-any.whl.metadata (29 kB)\n","Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2025.2)\n","Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2024.11.6)\n","Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (5.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser) (1.17.0)\n","Downloading dateparser-1.2.1-py3-none-any.whl (295 kB)\n","\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/295.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dateparser\n","Successfully installed dateparser-1.2.1\n"]}]},{"cell_type":"code","source":["from datetime import datetime, timedelta\n","import random\n","import time\n","import tempfile\n","import re\n","import os\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC"],"metadata":{"id":"krPVRomKhZB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# --- CREATE UNIQUE TEMP PROFILE FOR COLAB ---\n","temp_profile_dir = tempfile.mkdtemp()\n","print(f\"Using temporary Chrome profile at: {temp_profile_dir}\")\n","\n","# --- FUNCTION TO ENFORCE ENGLISH URLs ---\n","def enforce_english_url(url):\n","    if url is None:\n","        return None\n","    if 'hl=' in url:\n","        url = re.sub(r'hl=[^&]*', 'hl=en', url)\n","    else:\n","        if '?' in url:\n","            url += '&hl=en'\n","        else:\n","            url += '?hl=en'\n","    return url\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LX1dpCa-hiPS","executionInfo":{"status":"ok","timestamp":1749748063583,"user_tz":360,"elapsed":20,"user":{"displayName":"Stephanie Beaver","userId":"05177577234001440376"}},"outputId":"f960cb86-079e-4c35-ac01-e7484c47cb0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using temporary Chrome profile at: /tmp/tmp1o07lg7l\n"]}]},{"cell_type":"code","source":["## Search the store or company inside\"Double double quotations\" exactly as found on google reviews\n","## To search more than on area, include a , \"....\" for as many URLs as necessary. Don't scroll too far in or too far out\n","## Will not recognize if there are only one or two stores in the URL\n","\n","regional_search_urls = [\n","    \"https://www.google.com/maps/search/%22sportsman's+Warehouse%22+Arkansas/@35.1006432,-93.048218,8z?entry=ttu&g_ep=EgoyMDI1MDYxMS4wIKXMDSoASAFQAw%3D%3D\",\n","\n","]\n","\n"],"metadata":{"id":"O9tx60QQqUoj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" def dynamic_sleep(review_count):\n","    if review_count < 500:\n","        sleep_time = random.uniform(3, 5)\n","    elif review_count < 1000:\n","        sleep_time = random.uniform(5, 10)\n","    elif review_count < 1700:\n","        sleep_time = random.uniform(10, 15)\n","    elif review_count < 2000:\n","        sleep_time = random.uniform(15, 25)\n","    else:\n","        sleep_time = random.uniform(15, 25)\n","    print(f\"Sleeping for {sleep_time:.2f}s based on {review_count} reviews loaded\")\n","    time.sleep(sleep_time)\n","\n","# --- SETUP CHROME OPTIONS ---\n","chrome_options = Options()\n","chrome_options.add_argument(f\"--user-data-dir={temp_profile_dir}\")\n","chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n","chrome_options.add_argument(\"--start-maximized\")\n","chrome_options.add_argument(\"--no-sandbox\")\n","chrome_options.add_argument(\"--disable-dev-shm-usage\")\n","chrome_options.add_argument('--headless=new')\n","chrome_options.add_argument('--disable-gpu')\n","chrome_options.add_argument(\"--remote-debugging-port=9222\")\n","\n","\n","# --- INITIALIZE CHROME DRIVER ---\n","driver = webdriver.Chrome(options=chrome_options)\n","wait = WebDriverWait(driver, 20)\n","\n","# --- LOAD EXISTING SCRAPED URLS ---\n","scraped_log_path = \"/content/sample_data/scraped_urls.txt\"\n","try:\n","    with open(scraped_log_path, \"r\", encoding=\"utf-8\") as log_file:\n","        already_scraped = set(line.strip() for line in log_file.readlines())\n","except FileNotFoundError:\n","    already_scraped = set()\n","\n","# --- ENSURE HTML OUTPUT FILE EXISTS ---\n","output_file = \"/content/sample_data/sportsmans_scraped.html\"\n","if not os.path.exists(output_file):\n","    open(output_file, \"w\", encoding=\"utf-8\").close()  # create empty file if not there\n","\n","\n","\n","# --- STARTING URL ---\n","store_urls = set()\n","print(\"Starting multi-region scraping...\")\n","\n","\n","for region_url in regional_search_urls:\n","    print(f\"\\nüåé Navigating to region: {region_url}\")\n","    driver.get(region_url)\n","    time.sleep(random.uniform(40, 50))\n","\n","    try:\n","        side_panel = wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@role='feed']\")))\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Could not find store list panel for {region_url}: {e}\")\n","        continue\n","\n","    scroll_increment = 1000\n","    max_attempts = 1000\n","    no_change_counter = 0\n","    max_no_change_allowed = 3\n","    last_scroll_pos = driver.execute_script(\"return arguments[0].scrollTop\", side_panel)\n","\n","    print(f\"üìú Scrolling through results for: {region_url}\")\n","    for attempt in range(max_attempts):\n","        driver.execute_script(\"arguments[0].scrollTop += arguments[1]\", side_panel, scroll_increment)\n","        sleep_time = random.choice([random.uniform(5, 7), random.uniform(5, 10), random.uniform(10, 20)])\n","        print(f\"Scroll {attempt+1}, sleeping {sleep_time:.2f}s\")\n","        time.sleep(sleep_time)\n","\n","        new_scroll_pos = driver.execute_script(\"return arguments[0].scrollTop\", side_panel)\n","        if new_scroll_pos == last_scroll_pos:\n","            no_change_counter += 1\n","            if no_change_counter >= max_no_change_allowed:\n","                print(\"üõë No more new scroll detected.\")\n","                break\n","        else:\n","            no_change_counter = 0\n","            last_scroll_pos = new_scroll_pos\n","\n","        links = driver.find_elements(By.CSS_SELECTOR, \"a.hfpxzc\")\n","        for link in links:\n","            href = link.get_attribute('href')\n","            if href:\n","                store_urls.add(enforce_english_url(href))\n","\n","    print(f\"‚úÖ Done with region: {region_url} ‚Äî Total unique stores so far: {len(store_urls)}\")\n","\n","\n","# --- REVIEW SCRAPING FOR EACH STORE ---\n","store_locations = {}\n","\n","for i, store_url in enumerate(store_urls, start=1):\n","    if store_url in already_scraped:\n","        print(f\"‚è≠Ô∏è  Skipping already-scraped store: {store_url}\")\n","        continue\n","\n","    print(f\"\\nüéØ Visiting store {i}/{len(store_urls)}: {store_url}\")\n","    try:\n","        driver.get(store_url)\n","        time.sleep(random.uniform(5, 10))\n","\n","        try:\n","            address_element = wait.until(EC.presence_of_element_located(\n","                (By.XPATH, '//div[contains(@class, \"Io6YTe\") and contains(@class, \"fontBodyMedium\")]')\n","            ))\n","            store_location = address_element.text.strip()\n","            print(f\"Store location found: {store_location}\")\n","            store_locations[store_url] = store_location\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Could not find store location info: {e}\")\n","            store_location = \"Unknown\"\n","            store_locations[store_url] = store_location\n","\n","        reviews_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@aria-label, 'reviews')]\")))\n","        reviews_button.click()\n","        time.sleep(random.uniform(4, 6))\n","\n","        sort_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"Sort reviews\"]')))\n","        sort_button.click()\n","        time.sleep(random.uniform(4, 6))\n","\n","        newest_option = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@role=\"menuitemradio\" and .=\"Newest\"]')))\n","        newest_option.click()\n","        time.sleep(random.uniform(4, 6))\n","\n","        review_panel = wait.until(\n","            EC.presence_of_element_located(\n","                (By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n","            )\n","        )\n","        last_height = driver.execute_script(\"return arguments[0].scrollHeight\", review_panel)\n","\n","        scroll_attempts = 0\n","        max_scroll_attempts = 1000\n","        no_scroll_change_limit = 5\n","\n","        while scroll_attempts < max_scroll_attempts:\n","            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", review_panel)\n","            review_blocks = review_panel.find_elements(By.XPATH, './/div[contains(@class, \"jftiEf\")]')\n","            review_count = len(review_blocks)\n","            dynamic_sleep(review_count)\n","\n","            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", review_panel)\n","            if new_height == last_height:\n","                scroll_attempts += 1\n","                if scroll_attempts >= no_scroll_change_limit:\n","                    print(\"üîö No more reviews to load.\")\n","                    break\n","            else:\n","                last_height = new_height\n","                scroll_attempts = 0\n","\n","        print(f\"üìù Reviews loaded: {len(review_blocks)}\")\n","\n","        more_buttons = driver.find_elements(By.XPATH, \"//button[contains(text(), 'More')]\")\n","        print(f\"Found {len(more_buttons)} 'More' buttons to expand.\")\n","        for btn in more_buttons:\n","            try:\n","                driver.execute_script(\"arguments[0].click();\", btn)\n","                time.sleep(random.uniform(1, 2))\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Failed to click 'More' button: {e}\")\n","                continue\n","\n","        review_blocks = review_panel.find_elements(By.XPATH, './/div[contains(@class, \"jftiEf\")]')\n","\n","        # --- Build and append current store's reviews HTML ---\n","        store_html = f'\\n<!-- Store URL: {store_url} -->\\n'\n","        store_html += f'<!-- Store Location: {store_locations.get(store_url, \"Unknown\")} -->\\n'\n","        for review in review_blocks:\n","            html = review.get_attribute('outerHTML')\n","            store_html += html + \"\\n\"\n","\n","        with open(output_file, \"a\", encoding=\"utf-8\") as f:\n","            f.write(store_html)\n","\n","        print(f\"‚úÖ Collected {len(review_blocks)} reviews from store {i}\")\n","        print(f\"üíæ Saved progress after store {i}: {store_locations.get(store_url, 'Unknown')}\")\n","\n","        # Log this store as scraped\n","        with open(scraped_log_path, \"a\", encoding=\"utf-8\") as log_file:\n","            log_file.write(store_url + \"\\n\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå Error scraping store {store_url}: {e}\")\n","        continue\n","\n","print(f\"\\n‚ú® Finished scraping! All reviews saved to '{output_file}'\")\n","print(\"üßπ Quitting browser...\")\n","driver.quit()\n"],"metadata":{"id":"82q1_yLg6yAo","colab":{"base_uri":"https://localhost:8080/","height":679},"outputId":"0384b4d8-d938-4646-d1cc-04e32df55ef8","executionInfo":{"status":"error","timestamp":1749748182683,"user_tz":360,"elapsed":109752,"user":{"displayName":"Stephanie Beaver","userId":"05177577234001440376"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting multi-region scraping...\n","\n","üåé Navigating to region: https://www.google.com/maps/search/%22Sportsman's+Warehouse%22+Alaska/@61.0851128,-149.9888905,10z?authuser=0&hl=en&entry=ttu&g_ep=EgoyMDI1MDYwOS4xIKXMDSoASAFQAw%3D%3D\n","‚ö†Ô∏è Could not find store list panel for https://www.google.com/maps/search/%22Sportsman's+Warehouse%22+Alaska/@61.0851128,-149.9888905,10z?authuser=0&hl=en&entry=ttu&g_ep=EgoyMDI1MDYwOS4xIKXMDSoASAFQAw%3D%3D: Message: \n","Stacktrace:\n","#0 0x5c1078eaac9a <unknown>\n","#1 0x5c10789506e0 <unknown>\n","#2 0x5c10789a2117 <unknown>\n","#3 0x5c10789a2311 <unknown>\n","#4 0x5c10789f0ec4 <unknown>\n","#5 0x5c10789c7e5d <unknown>\n","#6 0x5c10789ee2cc <unknown>\n","#7 0x5c10789c7c03 <unknown>\n","#8 0x5c107899447b <unknown>\n","#9 0x5c10789950e1 <unknown>\n","#10 0x5c1078e6f44b <unknown>\n","#11 0x5c1078e7337f <unknown>\n","#12 0x5c1078e56f89 <unknown>\n","#13 0x5c1078e73f18 <unknown>\n","#14 0x5c1078e3b6df <unknown>\n","#15 0x5c1078e98308 <unknown>\n","#16 0x5c1078e984e6 <unknown>\n","#17 0x5c1078ea9b76 <unknown>\n","#18 0x7e61cf02bac3 <unknown>\n","\n","\n","üåé Navigating to region: https://www.google.com/maps/search/%22Sportsman's+Warehouse%22+Alaska/@58.3883152,-138.4587388,6z?authuser=0&hl=en&entry=ttu&g_ep=EgoyMDI1MDYwOS4xIKXMDSoASAFQAw%3D%3D\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-3560383103>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nüåé Navigating to region: {region_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m    \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m    \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m    \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["###For future use- use this section in place of the previous one\n","## This one has the date set up so that it will only collect reviews less than 1 month ago...\n","# --- STARTING URL WITH WIDE ZOOM ---\n","search_url = \"https://www.google.com/maps/search/sportsmans+warehouse/@39.8283,-119.6732484,3z?hl=en%22&entry=ttu&g_ep=EgoyMDI1MDYwMS4wIKXMDSoASAFQAw%3D%3D\"\n","driver.get(search_url)\n","time.sleep(random.uniform(5, 10))\n","\n","# --- SCROLL THROUGH STORE LIST TO COLLECT STORE URLs ---\n","side_panel = wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@role='feed']\")))\n","scroll_increment = 1000\n","max_attempts = 1000\n","no_change_counter = 0\n","max_no_change_allowed = 3\n","last_scroll_pos = driver.execute_script(\"return arguments[0].scrollTop\", side_panel)\n","\n","store_urls = set()\n","print(\"Scrolling through store list...\")\n","\n","for attempt in range(max_attempts):\n","    driver.execute_script(\"arguments[0].scrollTop += arguments[1]\", side_panel, scroll_increment)\n","    sleep_time = random.choice([random.uniform(5, 10), random.uniform(10, 20), random.uniform(20, 40)])\n","    print(f\"Scroll {attempt+1}, sleeping {sleep_time:.2f}s\")\n","    time.sleep(sleep_time)\n","\n","    new_scroll_pos = driver.execute_script(\"return arguments[0].scrollTop\", side_panel)\n","    if new_scroll_pos == last_scroll_pos:\n","        no_change_counter += 1\n","        if no_change_counter >= max_no_change_allowed:\n","            break\n","    else:\n","        no_change_counter = 0\n","        last_scroll_pos = new_scroll_pos\n","\n","    links = driver.find_elements(By.CSS_SELECTOR, \"a.hfpxzc\")\n","    for link in links:\n","        href = link.get_attribute('href')\n","        if href:\n","            store_urls.add(enforce_english_url(href))\n","\n","    print(f\"Unique stores found so far: {len(store_urls)}\")\n","\n","# --- REVIEW SCRAPING FOR EACH STORE -Added the date limits to go back one month can change dates from 30 to whatever number of days you need\n","store_locations = {}\n","one_month_ago = datetime.now() - timedelta(days=30)\n","\n","for i, store_url in enumerate(store_urls, start=1):\n","    if store_url in already_scraped:\n","        print(f\"‚è≠Ô∏è  Skipping already-scraped store: {store_url}\")\n","        continue\n","\n","    print(f\"\\nüéØ Visiting store {i}/{len(store_urls)}: {store_url}\")\n","    try:\n","        driver.get(store_url)\n","        time.sleep(random.uniform(5, 10))\n","\n","        try:\n","            address_element = wait.until(EC.presence_of_element_located(\n","                (By.XPATH, '//div[contains(@class, \"Io6YTe\") and contains(@class, \"fontBodyMedium\")]')\n","            ))\n","            store_location = address_element.text.strip()\n","            print(f\"Store location found: {store_location}\")\n","            store_locations[store_url] = store_location\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Could not find store location info: {e}\")\n","            store_location = \"Unknown\"\n","            store_locations[store_url] = store_location\n","\n","        reviews_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@aria-label, 'reviews')]\")))\n","        reviews_button.click()\n","        time.sleep(random.uniform(4, 6))\n","\n","        sort_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"Sort reviews\"]')))\n","        sort_button.click()\n","        time.sleep(random.uniform(4, 6))\n","\n","        newest_option = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@role=\"menuitemradio\" and .=\"Newest\"]')))\n","        newest_option.click()\n","        time.sleep(random.uniform(4, 6))\n","\n","        review_panel = wait.until(\n","            EC.presence_of_element_located(\n","                (By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n","            )\n","        )\n","        last_height = driver.execute_script(\"return arguments[0].scrollHeight\", review_panel)\n","\n","        scroll_attempts = 0\n","        max_scroll_attempts = 1000\n","        no_scroll_change_limit = 5\n","\n","        while scroll_attempts < max_scroll_attempts:\n","            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", review_panel)\n","            review_blocks = review_panel.find_elements(By.XPATH, './/div[contains(@class, \"jftiEf\")]')\n","            review_count = len(review_blocks)\n","            dynamic_sleep(review_count)\n","\n","            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", review_panel)\n","            if new_height == last_height:\n","                scroll_attempts += 1\n","                if scroll_attempts >= no_scroll_change_limit:\n","                    print(\"üîö No more reviews to load.\")\n","                    break\n","            else:\n","                last_height = new_height\n","                scroll_attempts = 0\n","\n","        more_buttons = driver.find_elements(By.XPATH, \"//button[contains(text(), 'More')]\")\n","        for btn in more_buttons:\n","            try:\n","                driver.execute_script(\"arguments[0].click();\", btn)\n","                time.sleep(random.uniform(1, 2))\n","            except Exception as e:\n","                continue\n","\n","        review_blocks = review_panel.find_elements(By.XPATH, './/div[contains(@class, \"jftiEf\")]')\n","        filtered_reviews_html = \"\"\n","        valid_review_count = 0\n","\n","        for review in review_blocks:\n","            try:\n","                review_html = review.get_attribute(\"outerHTML\")\n","                date_element = review.find_element(By.XPATH, './/span[contains(@class, \"rsqaWe\")]')\n","                date_text = date_element.text.strip()\n","                parsed_date = dateparser.parse(date_text)\n","                if parsed_date and parsed_date >= one_month_ago:\n","                    filtered_reviews_html += review_html + \"\\n\"\n","                    valid_review_count += 1\n","            except Exception as e:\n","                continue\n","\n","        store_html = f'\\n<!-- Store URL: {store_url} -->\\n'\n","        store_html += f'<!-- Store Location: {store_locations.get(store_url, \"Unknown\")} -->\\n'\n","        store_html += filtered_reviews_html\n","\n","        with open(output_file, \"a\", encoding=\"utf-8\") as f:\n","            f.write(store_html)\n","\n","        print(f\"‚úÖ Appended {valid_review_count} reviews from past month.\")\n","        with open(scraped_log_path, \"a\", encoding=\"utf-8\") as log_file:\n","            log_file.write(store_url + \"\\n\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå Error scraping store {store_url}: {e}\")\n","        continue\n","\n","print(f\"\\n‚ú® Finished scraping! All reviews saved to '{output_file}'\")\n","print(\"üßπ Quitting browser...\")\n","driver.quit()\n"],"metadata":{"id":"kyShcrTF_vpd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UZBSSSq13LfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ubpEgxqt3Lcq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4ZBZYcD73LZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kXtoRU-a3LSm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"20lzkLWh3LOx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UdYQguB23LKm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KbFSvmCl3LBb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"o1m8jwGL3K-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a6JYtiWv3K2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"snDmQdSu3KsH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import textwrap"],"metadata":{"id":"Je7eIoMh38oU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" def dynamic_sleep(review_count):\n","    if review_count < 500:\n","        sleep_time = random.uniform(3, 5)\n","    elif review_count < 1000:\n","        sleep_time = random.uniform(5, 10)\n","    elif review_count < 1700:\n","        sleep_time = random.uniform(10, 15)\n","    elif review_count < 2000:\n","        sleep_time = random.uniform(15, 25)\n","    else:\n","        sleep_time = random.uniform(15, 25)\n","    print(f\"Sleeping for {sleep_time:.2f}s based on {review_count} reviews loaded\")\n","    time.sleep(sleep_time)\n","\n","# --- SETUP CHROME OPTIONS ---\n","chrome_options = Options()\n","chrome_options.add_argument(f\"--user-data-dir={temp_profile_dir}\")\n","chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n","chrome_options.add_argument(\"--start-maximized\")\n","chrome_options.add_argument(\"--no-sandbox\")\n","chrome_options.add_argument(\"--disable-dev-shm-usage\")\n","chrome_options.add_argument('--headless=new')\n","chrome_options.add_argument('--disable-gpu')\n","\n","# --- INITIALIZE CHROME DRIVER ---\n","driver = webdriver.Chrome(options=chrome_options)\n","wait = WebDriverWait(driver, 20)\n","\n","# --- LOAD EXISTING SCRAPED URLS ---\n","scraped_log_path = \"/content/sample_data/scraped_urls.txt\"\n","try:\n","    with open(scraped_log_path, \"r\", encoding=\"utf-8\") as log_file:\n","        already_scraped = set(line.strip() for line in log_file.readlines())\n","except FileNotFoundError:\n","    already_scraped = set()\n","\n","# --- ENSURE HTML OUTPUT FILE EXISTS ---\n","output_file = \"/content/sample_data/sportsmans_scraped.html\"\n","if not os.path.exists(output_file):\n","    open(output_file, \"w\", encoding=\"utf-8\").close()  # create empty file if not there\n","\n","# --- STARTING URL ---\n","store_urls = set()\n","print(\"Starting multi-region scraping...\")\n","\n","for region_url in regional_search_urls:\n","    print(f\"\\nüåé Navigating to region: {region_url}\")\n","    driver.get(region_url)\n","    time.sleep(random.uniform(5, 10))\n","\n","try:\n","    # Try getting the scrollable panel using a more robust reference\n","    links_panel = wait.until(\n","        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[aria-label][jslog]\"))\n","    )\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Still no scrollable container found in: {region_url}\")\n","    with open(\"failed_region_dump.html\", \"w\", encoding=\"utf-8\") as f:\n","        f.write(driver.page_source)\n","    continue\n","\n","\n","    print(f\"üìú Scrolling and extracting store URLs for: {region_url}\")\n","\n","    scroll_increment = 1000\n","    max_attempts = 1000\n","    no_change_counter = 0\n","    max_no_change_allowed = 3\n","    last_scroll_pos = driver.execute_script(\"return arguments[0].scrollTop\", side_panel)\n","\n","    for attempt in range(max_attempts):\n","        driver.execute_script(\"arguments[0].scrollTop += arguments[1]\", side_panel, scroll_increment)\n","        sleep_time = random.choice([random.uniform(3, 5), random.uniform(5, 10), random.uniform(10, 20)])\n","        print(f\"Scroll {attempt+1}, sleeping {sleep_time:.2f}s\")\n","        time.sleep(sleep_time)\n","\n","        new_scroll_pos = driver.execute_script(\"return arguments[0].scrollTop\", side_panel)\n","        if new_scroll_pos == last_scroll_pos:\n","            no_change_counter += 1\n","            if no_change_counter >= max_no_change_allowed:\n","                print(\"üõë No more new scroll detected.\")\n","                break\n","        else:\n","            no_change_counter = 0\n","            last_scroll_pos = new_scroll_pos\n","\n","    links = driver.find_elements(By.CSS_SELECTOR, \"a.hfpxzc\")\n","    new_links = 0\n","    for link in links:\n","        href = link.get_attribute('href')\n","        if href and enforce_english_url(href) not in store_urls:\n","            store_urls.add(enforce_english_url(href))\n","            new_links += 1\n","\n","    print(f\"‚úÖ Region done: {region_url}\")\n","    print(f\"‚ûï Found {new_links} new store URLs ‚Äî total so far: {len(store_urls)}\")\n","\n","\n","# --- REVIEW SCRAPING FOR EACH STORE ---\n","store_locations = {}\n","\n","for i, store_url in enumerate(store_urls, start=1):\n","    if store_url in already_scraped:\n","        print(f\"‚è≠Ô∏è  Skipping already-scraped store: {store_url}\")\n","        continue\n","\n","    print(f\"\\nüéØ Visiting store {i}/{len(store_urls)}: {store_url}\")\n","    try:\n","        driver.get(store_url)\n","        time.sleep(random.uniform(5, 10))\n","\n","        try:\n","            address_element = wait.until(EC.presence_of_element_located(\n","                (By.XPATH, '//div[contains(@class, \"Io6YTe\") and contains(@class, \"fontBodyMedium\")]')\n","            ))\n","            store_location = address_element.text.strip()\n","            print(f\"Store location found: {store_location}\")\n","            store_locations[store_url] = store_location\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Could not find store location info: {e}\")\n","            store_location = \"Unknown\"\n","            store_locations[store_url] = store_location\n","\n","        reviews_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@aria-label, 'reviews')]\")))\n","        reviews_button.click()\n","        time.sleep(random.uniform(4, 6))\n","\n","        sort_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"Sort reviews\"]')))\n","        sort_button.click()\n","        time.sleep(random.uniform(4, 6))\n","\n","        newest_option = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@role=\"menuitemradio\" and .=\"Newest\"]')))\n","        newest_option.click()\n","        time.sleep(random.uniform(4, 6))\n","\n","        review_panel = wait.until(\n","            EC.presence_of_element_located(\n","                (By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n","            )\n","        )\n","        last_height = driver.execute_script(\"return arguments[0].scrollHeight\", review_panel)\n","\n","        scroll_attempts = 0\n","        max_scroll_attempts = 1000\n","        no_scroll_change_limit = 5\n","\n","        while scroll_attempts < max_scroll_attempts:\n","            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", review_panel)\n","            review_blocks = review_panel.find_elements(By.XPATH, './/div[contains(@class, \"jftiEf\")]')\n","            review_count = len(review_blocks)\n","            dynamic_sleep(review_count)\n","\n","            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", review_panel)\n","            if new_height == last_height:\n","                scroll_attempts += 1\n","                if scroll_attempts >= no_scroll_change_limit:\n","                    print(\"üîö No more reviews to load.\")\n","                    break\n","            else:\n","                last_height = new_height\n","                scroll_attempts = 0\n","\n","        print(f\"üìù Reviews loaded: {len(review_blocks)}\")\n","\n","        more_buttons = driver.find_elements(By.XPATH, \"//button[contains(text(), 'More')]\")\n","        print(f\"Found {len(more_buttons)} 'More' buttons to expand.\")\n","        for btn in more_buttons:\n","            try:\n","                driver.execute_script(\"arguments[0].click();\", btn)\n","                time.sleep(random.uniform(1, 2))\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Failed to click 'More' button: {e}\")\n","                continue\n","\n","        review_blocks = review_panel.find_elements(By.XPATH, './/div[contains(@class, \"jftiEf\")]')\n","\n","        # --- Build and append current store's reviews HTML ---\n","        store_html = f'\\n<!-- Store URL: {store_url} -->\\n'\n","        store_html += f'<!-- Store Location: {store_locations.get(store_url, \"Unknown\")} -->\\n'\n","        for review in review_blocks:\n","            html = review.get_attribute('outerHTML')\n","            store_html += html + \"\\n\"\n","\n","        with open(output_file, \"a\", encoding=\"utf-8\") as f:\n","            f.write(store_html)\n","\n","        print(f\"‚úÖ Collected {len(review_blocks)} reviews from store {i}\")\n","        print(f\"üíæ Saved progress after store {i}: {store_locations.get(store_url, 'Unknown')}\")\n","\n","        # Log this store as scraped\n","        with open(scraped_log_path, \"a\", encoding=\"utf-8\") as log_file:\n","            log_file.write(store_url + \"\\n\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå Error scraping store {store_url}: {e}\")\n","        continue\n","\n","print(f\"\\n‚ú® Finished scraping! All reviews saved to '{output_file}'\")\n","print(\"üßπ Quitting browser...\")\n","driver.quit()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"id":"m8A9A6bZs9ag","executionInfo":{"status":"error","timestamp":1749692279184,"user_tz":360,"elapsed":42088,"user":{"displayName":"Stephanie Beaver","userId":"05177577234001440376"}},"outputId":"96b5ed24-9358-4b4f-e413-824b0059844e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting multi-region scraping...\n","\n","üåé Navigating to region: https://www.google.com/maps/search/%22Sportsman's+Warehouse%22+Alaska/@61.6390309,-147.7070618,6z?authuser=0&hl=en&entry=ttu&g_ep=EgoyMDI1MDYwMy4wIKXMDSoASAFQAw%3D%3D\n","\n","üåé Navigating to region: https://www.google.com/maps/search/%22Sportsman's+Warehouse%22+Alaska/@59.1998449,-135.2815249,7z?authuser=0&hl=en&entry=ttu&g_ep=EgoyMDI1MDYwNC4wIKXMDSoASAFQAw%3D%3D\n","\n","üåé Navigating to region: https://www.google.com/maps/search/%22Sportsman's+Warehouse%22/@48.1065043,-122.9546184,10z?authuser=0&hl=en&entry=ttu&g_ep=EgoyMDI1MDYwMy4wIKXMDSoASAFQAw%3D%3D\n","\n","üåé Navigating to region: https://www.google.com/maps/search/%22Sportsman's+Warehouse%22+VA/@38.209683,-80.9469872,8z?authuser=0&hl=en&entry=ttu&g_ep=EgoyMDI1MDYwMy4wIKXMDSoASAFQAw%3D%3D\n"]},{"output_type":"error","ename":"SyntaxError","evalue":"'continue' not properly in loop (<ipython-input-7-3490244468>, line 60)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-3490244468>\"\u001b[0;36m, line \u001b[0;32m60\u001b[0m\n\u001b[0;31m    continue\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'continue' not properly in loop\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ba2l1q3TtQug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CurYpQkJtQrE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mkGuj7XC6x1m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LF4tSBla_vnY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"S50OTbn2_vlK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5L-ma8Nb_vf9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RkIOHkJy_vcu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vHJ6nPkngDAF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"My3mD-CsvMX4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Sb0vcwSa-Ob5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"l-KbrDTA-ONX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sIjd_OdTvMTy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-HZy6p84ZNwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YdNpa3iSZNqj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZgOrj7Gb5_Ge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749130846773,"user_tz":360,"elapsed":26466,"user":{"displayName":"Stephanie Beaver","userId":"05177577234001440376"}},"outputId":"cd141853-9abe-43c5-c55a-fb2f3a5f326b","id":"-05FRzkKrpr8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["The following code *SHOULD BE*** the updated code to convert the HTML to CSV - it inclydes the code to make the location column= the city of the store the review came from....."],"metadata":{"id":"WlRHheD66aYd"}},{"cell_type":"markdown","source":[],"metadata":{"id":"lLvvADQ_6aUm"}},{"cell_type":"code","source":[],"metadata":{"id":"izWSjze0tDPN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dE3nXusztDMT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wLiqIt9PtDJC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"63Pn-YhVtDGa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OR3C1Ux-tDCl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"naS1OecZtC_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3oEx5XXitC8D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JNktVpD7qurg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-fCHO0W7qupy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bUzaLelYquok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9Yk-qIyDqukl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"siu3dpuzqujV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"VMBBmkbuPRoE"}},{"cell_type":"code","source":[],"metadata":{"id":"G_L6is_7qufb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MIsFP9ahqudL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aHDyL-7CquYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"unkVIlurquVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WrX_s0BMquSG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bjhjsJu_quOk"},"execution_count":null,"outputs":[]}]}